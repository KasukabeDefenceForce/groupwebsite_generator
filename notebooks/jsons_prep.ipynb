{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to the desired location\n",
    "#temporary, only for local\n",
    "# import os\n",
    "# os.chdir(\"/home/bumblebealu/groupwebsite_generator/\")\n",
    "# os.chdir(\"/Users/harshul/website clone/harshul/test/groupwebsite_generator\")\n",
    "# os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_member_jsons(members_directory, output_directory):\n",
    "    output_file = 'people_list.json'  # Output file name\n",
    "    output_path = os.path.join(output_directory, output_file)\n",
    "\n",
    "    # Clear the output file if it exists\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, 'w') as output:\n",
    "            output.truncate()\n",
    "\n",
    "    # Create the output file if it doesn't exist\n",
    "    with open(output_path, 'a') as output:\n",
    "        if os.stat(output_path).st_size == 0:\n",
    "            # Write the initial JSON structure if the file was just created\n",
    "            json.dump({\"people\": [], \"people_directories\": []}, output)\n",
    "\n",
    "    for member_dir in os.listdir(members_directory):\n",
    "        member_path = os.path.join(members_directory, member_dir)\n",
    "        if os.path.isdir(member_path):\n",
    "            jsons_directory = os.path.join(member_path, 'jsons')\n",
    "            if os.path.isdir(jsons_directory):\n",
    "                for json_file in os.listdir(jsons_directory):\n",
    "                    if json_file.endswith('info.json'):\n",
    "                        json_path = os.path.join(jsons_directory, json_file)\n",
    "                        with open(json_path, 'r') as file:\n",
    "                            data = json.load(file)\n",
    "                            if data.get('display'):\n",
    "                                id_key = data.get('id')\n",
    "                                with open(output_path, 'r+') as output:\n",
    "                                    output_data = json.load(output)\n",
    "                                    output_data['people'].append(f\"members/{id_key}/{id_key}.json\")\n",
    "                                    output_data['people_directories'].append(f\"members/{id_key}/jsons\")\n",
    "                                    output.seek(0)  # Move the file pointer to the beginning of the file\n",
    "                                    output.truncate()  # Clear the file content\n",
    "                                    json.dump(output_data, output, indent='        ')\n",
    "                                    output.write('\\n')  # Append a newline character\n",
    "\n",
    "# Specify the directory containing the \"members\" directory\n",
    "members_directory = '../group-data/members/'\n",
    "\n",
    "# Specify the output directory where you want the \"ids.json\" file to be saved\n",
    "output_directory = '../group-data/website_data/'\n",
    "\n",
    "# Call the function to process the member JSON files\n",
    "process_member_jsons(members_directory, output_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending Individual Member's JSONs into one\n",
    "###### Each member will have their own combined JSON that contains awards.json, basic_info.json, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the list of directories and JSON files from the people_list.json file\n",
    "with open('../group-data/website_data/people_list.json') as f:\n",
    "    file_list = json.load(f)\n",
    "\n",
    "# Get the directory path\n",
    "dir_path = os.path.dirname('../group-data/website_data')\n",
    "\n",
    "# Loop through each directory in the list\n",
    "for directory in file_list['people_directories']:\n",
    "    # Get the directory name\n",
    "    directory_name = os.path.basename(directory)\n",
    "    # Remove any file extension from the directory name\n",
    "    directory_name = directory_name.split('.')[0]\n",
    "    # Create an empty dictionary to hold the combined JSON data for this directory\n",
    "    combined_data = {}\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(os.path.join(dir_path, directory)):\n",
    "        # Check if the file is a JSON file\n",
    "        if filename.endswith('.json'):\n",
    "            # Load the JSON data from the file\n",
    "            with open(os.path.join(dir_path, directory, filename)) as f:\n",
    "                json_data = json.load(f)\n",
    "            # If the JSON data is a dictionary, update the combined_data dictionary with new key-value pairs\n",
    "            if isinstance(json_data, dict):\n",
    "                for key, value in json_data.items():\n",
    "                    if key not in combined_data:\n",
    "                        combined_data[key] = value\n",
    "            # If the JSON data is a list, loop through each element and update the combined_data dictionary with new key-value pairs\n",
    "            elif isinstance(json_data, list):\n",
    "                for item in json_data:\n",
    "                    if isinstance(item, dict):\n",
    "                        for key, value in item.items():\n",
    "                            if key not in combined_data:\n",
    "                                combined_data[key] = value\n",
    "    # Write the combined JSON data to a new file in the same directory as the original files\n",
    "    with open(os.path.join(dir_path, directory.split('/')[0],directory.split('/')[1], directory.split('/')[1]+'.json'), 'w') as f:\n",
    "        f.write(\"[\")  # Add opening square bracket\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "        f.write(\"]\")  # Add closing square bracket\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining People Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"common\" folder if it doesn't exist\n",
    "common_folder_path = '../group-data/members/common/'\n",
    "os.makedirs(common_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_people_by_category(category):\n",
    "    people = []\n",
    "\n",
    "    # Load the list of JSON files\n",
    "    with open('../group-data/website_data/people_list.json') as f:\n",
    "        file_list = json.load(f)\n",
    "\n",
    "    # Get the directory path\n",
    "    dir_path = os.path.dirname('../group-data/website_data')\n",
    "\n",
    "    # Loop through each file in the list\n",
    "    for file_name in file_list['people']:\n",
    "        # Construct the full path to the JSON file\n",
    "        json_path = os.path.join(dir_path, file_name)\n",
    "        with open(json_path) as f:\n",
    "            # Load the data from the file\n",
    "            data = json.load(f)\n",
    "            # Check if the data has the specified category\n",
    "            if any(\"category\" in item and item[\"category\"] == category for item in data):\n",
    "                people.extend([item for item in data if \"category\" in item and item[\"category\"] == category])\n",
    "\n",
    "    # Generate the output file path based on the category\n",
    "    output_file = f\"../group-data/members/common/{category.lower().replace(' ', '_')}.json\"\n",
    "\n",
    "    # Write the combined data to the output JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(people, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_people_by_category(\"Faculty\")\n",
    "filter_people_by_category(\"Undergraduate Students\")\n",
    "filter_people_by_category(\"Graduate Students\")\n",
    "filter_people_by_category(\"Postdoctoral Researchers\")\n",
    "filter_people_by_category(\"Researchers\")\n",
    "filter_people_by_category(\"Research Software Engineer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"common\" folder if it doesn't exist\n",
    "combined_research_path = '../group-data/website_data/research/sub_research_data/combined'\n",
    "os.makedirs(combined_research_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file that lists the research categories\n",
    "with open(\"../group-data/website_data/research_categories.json\") as f:\n",
    "    research_categories = json.load(f)[\"research_categories\"]\n",
    "\n",
    "# Loop through each research category\n",
    "for category_path in research_categories:\n",
    "    # Prepend the base directory path to the category path\n",
    "    category_path = os.path.join(\"..\", \"group-data\", \"website_data\", category_path)\n",
    "\n",
    "    # Initialize an empty list to hold the data from each JSON file in the category\n",
    "    category_data = []\n",
    "\n",
    "    # Loop through each file in the category directory\n",
    "    for filename in os.listdir(category_path):\n",
    "        # Check if the file is a JSON file and not 'about.json'\n",
    "        if filename.endswith(\".json\") and filename != \"about.json\":\n",
    "            # Open the file and load its contents as JSON\n",
    "            with open(os.path.join(category_path, filename)) as f:\n",
    "                json_data = json.load(f)\n",
    "            # Check the value of the \"display\" key\n",
    "            if json_data.get(\"display\") == True:\n",
    "                # Extract the date value and convert it to a datetime object\n",
    "                json_date = json_data.get(\"date\")  # Replace \"date\" with the actual key holding the date value\n",
    "                if json_date:\n",
    "                    date_object = datetime.datetime.strptime(json_date, \"%m-%d-%Y\")\n",
    "                    # Append the date and JSON data to the category list\n",
    "                    category_data.append((date_object, json_data))\n",
    "\n",
    "    # Sort the category data based on the date in descending order\n",
    "    category_data.sort(key=lambda x: x[0] if x[0] is not None else datetime.datetime.min, reverse=True)\n",
    "\n",
    "    # Check if 'about.json' exists in the category directory\n",
    "    about_file_path = os.path.join(category_path, \"about.json\")\n",
    "    if os.path.exists(about_file_path):\n",
    "        # Open 'about.json' and load its contents as JSON\n",
    "        with open(about_file_path) as f:\n",
    "            about_data = json.load(f)\n",
    "        # Insert the 'about.json' data at the beginning of the category list\n",
    "        category_data.insert(0, (None, about_data))  # None for date in about.json\n",
    "\n",
    "\n",
    "    # Write the combined data to a new JSON file for this category\n",
    "    category_name = os.path.basename(category_path)\n",
    "    with open(f\"../group-data/website_data/research/sub_research_data/combined/{category_name}.json\", \"w\") as f:\n",
    "        sorted_category_data = [data[1] for data in category_data]\n",
    "        json.dump(sorted_category_data, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path where the JSON files are located\n",
    "directory_path = \"../group-data/website_data/news\"\n",
    "\n",
    "# Initialize an empty list to hold the data from each JSON file\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a JSON file\n",
    "    if filename.endswith(\".json\") and filename != \"combined_news.json\":\n",
    "        # Open the file and load its contents as JSON\n",
    "        with open(os.path.join(directory_path, filename)) as f:\n",
    "            json_data = json.load(f)\n",
    "        # Check the value of the \"display\" key\n",
    "        if json_data.get(\"display\"):\n",
    "            # Extract the date value and convert it to a datetime object\n",
    "            json_date = json_data.get(\"date\")  # Replace \"date\" with the actual key holding the date value\n",
    "            if json_date:\n",
    "                date_object = datetime.datetime.strptime(json_date, \"%m-%d-%Y\")\n",
    "                # Append the date and JSON data to the combined list\n",
    "                combined_data.append((date_object, json_data))\n",
    "        else:\n",
    "            # Exclude data with \"display\" value of False\n",
    "            print(f\"Skipping '{filename}' as display is False.\")\n",
    "            \n",
    "# Sort the combined data based on the date in descending order\n",
    "combined_data.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Extract only the JSON data from the sorted list\n",
    "sorted_combined_data = [data[1] for data in combined_data]\n",
    "\n",
    "# Write the combined and sorted data to a new JSON file in the same directory\n",
    "combined_file_path = os.path.join(directory_path, \"combined_news.json\")\n",
    "with open(combined_file_path, \"w\") as f:\n",
    "    json.dump(sorted_combined_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
