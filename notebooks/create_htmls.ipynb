{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "GROUP_DATA_DIR = Path(\"../..//group-data\")\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"abhinav.github.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Function to create proper HTML file names by replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def page_link(a):\n",
    "    \"\"\"Return the HTML file name after replacing blank spaces(\" \") with underscores(\"-\")\"\"\"\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for looping through JSON files and loading their content into the 'data' dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loading_json_files(json_file_names):\n",
    "    \"\"\"\n",
    "    Load data from JSON files specified in a list of file names.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    json_file_names : list of str\n",
    "        A list of file names (without extension) to load as JSON.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict \n",
    "        A dictionary where keys are file names and values are the corresponding JSON data.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for json_file in json_file_names:\n",
    "        json_file_path = WEBSITE_DATA_PATH / f\"{json_file}.json\"\n",
    "    \n",
    "        try:\n",
    "            with open(json_file_path, \"r\") as json_var:\n",
    "                data[json_file] = json.load(json_var)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_page(template, html, **kwargs):\n",
    "    \"\"\"\n",
    "    Create an HTML page using a Jinja2 template and save it to a specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    template : str\n",
    "        The filename of the Jinja2 template to be used.\n",
    "    html : str\n",
    "        The filename of the HTML file to be generated.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments to be passed to the Jinja2 template for rendering.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    page_template = environment.get_template(template)\n",
    "    page_html_path = HOSTING_PATH / html\n",
    "    page_content = page_template.render(**kwargs)\n",
    "    with open(page_html_path, mode='w', encoding='utf-8') as page:\n",
    "        page.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_content_from_files(columns):\n",
    "    \"\"\"\n",
    "    Load content data from JSON files into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str\n",
    "        A list of column names to extract from the JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the specified columns from the loaded JSON files.\n",
    "\n",
    "    \"\"\"\n",
    "    content_data = {col: [] for col in columns}\n",
    "\n",
    "    for json_file in os.listdir(CONTENT_DIR_PATH):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(CONTENT_DIR_PATH, json_file)\n",
    "            with open(json_path, \"r\") as file:\n",
    "                info = json.load(file)\n",
    "                # Only load those articles where display is True\n",
    "                if info.get(\"display\"):\n",
    "                    for col in columns:\n",
    "                        content_data[col].append(info.get(col))\n",
    "\n",
    "    content_df = pd.DataFrame(content_data)\n",
    "    content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "    return content_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Latest Content for Each Category from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_content_df(content_df):\n",
    "    \"\"\"\n",
    "    Extract the latest content for each category from a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content_df : pandas.DataFrame\n",
    "        The input DataFrame containing content information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the latest content for each category.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
    "    sorted_content_df = content_df.sort_values(\n",
    "        by=[\"category\", \"date\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    # Get the first row for each category using groupby and head\n",
    "    latest_content_df = sorted_content_df.groupby(\"category\").head(1).copy()\n",
    "    latest_content_df[\"date\"] = pd.to_datetime(\n",
    "        latest_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
    "    )\n",
    "    latest_content_df = latest_content_df.sort_values(by=\"date\", ascending=False)\n",
    "\n",
    "    return latest_content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of JSON files to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\n",
    "    \"general\",\n",
    "    \"homepage\",\n",
    "    \"research\",\n",
    "    \"support\",\n",
    "    \"contact\",\n",
    "]\n",
    "\n",
    "#Function Call\n",
    "data = loading_json_files(json_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>cover_image</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reu_student_announcement</td>\n",
       "      <td>News</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>[news, research, Internship]</td>\n",
       "      <td>Summer REU Students Join Kerzendorf Group</td>\n",
       "      <td>website_files/images/article_content/nsflogo.jpg</td>\n",
       "      <td>Two undergraduate research assistants have joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snr0509_josh_paper</td>\n",
       "      <td>Astrophysical Transients</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>[research, news]</td>\n",
       "      <td>A comprehensive SN Ia companion search in SNR ...</td>\n",
       "      <td>website_files/images/article_content/snr0509_v...</td>\n",
       "      <td>A search for a surviving companion to a 400 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midsure22_poster_bea</td>\n",
       "      <td>Computational Metascience</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>[research]</td>\n",
       "      <td>MIDSURE 2022</td>\n",
       "      <td>website_files/images/article_content/bea_midsu...</td>\n",
       "      <td>Poster presentation at the Mid-Michigan Sympos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id                   category       date  \\\n",
       "1  reu_student_announcement                       News 2023-06-23   \n",
       "3        snr0509_josh_paper   Astrophysical Transients 2023-05-28   \n",
       "4      midsure22_poster_bea  Computational Metascience 2022-07-22   \n",
       "\n",
       "                           tags  \\\n",
       "1  [news, research, Internship]   \n",
       "3              [research, news]   \n",
       "4                    [research]   \n",
       "\n",
       "                                               title  \\\n",
       "1          Summer REU Students Join Kerzendorf Group   \n",
       "3  A comprehensive SN Ia companion search in SNR ...   \n",
       "4                                       MIDSURE 2022   \n",
       "\n",
       "                                         cover_image  \\\n",
       "1   website_files/images/article_content/nsflogo.jpg   \n",
       "3  website_files/images/article_content/snr0509_v...   \n",
       "4  website_files/images/article_content/bea_midsu...   \n",
       "\n",
       "                                   short_description  \n",
       "1  Two undergraduate research assistants have joi...  \n",
       "3  A search for a surviving companion to a 400 ye...  \n",
       "4  Poster presentation at the Mid-Michigan Sympos...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Needed columns for homepage\n",
    "article_columns_initial = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\",\n",
    "]\n",
    "content_df = load_content_from_files(article_columns_initial)\n",
    "latest_content_df = get_latest_content_df(content_df)\n",
    "latest_content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page('homepage.html.j2', 'Index.html', general=data[\"general\"], homepage=data[\"homepage\"], recent_content=latest_content_df.to_dict(orient=\"records\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parse member data from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load education data\n",
    "def load_education_experience_data(edu_exp_dir):\n",
    "    edu_exp_list = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "    valid_groups = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "    valid_institution = \"Michigan State University\"\n",
    "    for file_name in file_names:\n",
    "        file_path = edu_exp_dir / file_name\n",
    "        if file_path.exists():\n",
    "            # Reading JSON data directly into a DataFrame\n",
    "            df = pd.read_json(file_path)\n",
    "            \n",
    "            # filtering based on group and institution\n",
    "            filtered_df = filter_data(df, valid_groups, valid_institution)\n",
    "            \n",
    "            edu_exp_list.append(filtered_df)\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist\")\n",
    "\n",
    "    if edu_exp_list:\n",
    "        edu_exp_df = pd.concat(edu_exp_list, ignore_index=True)\n",
    "    else:\n",
    "        edu_exp_df = pd.DataFrame()\n",
    "\n",
    "    # if start_date column exists, fill with NaN if it doesn't\n",
    "    if 'start_date' not in edu_exp_df:\n",
    "        edu_exp_df['start_date'] = pd.NaT\n",
    "    \n",
    "    # Convert start_date to datetime format\n",
    "    edu_exp_df['start_date'] = pd.to_datetime(edu_exp_df['start_date'], errors='coerce')\n",
    "    \n",
    "    # Sort the DataFrame based on start_date\n",
    "    edu_exp_df = edu_exp_df.sort_values(by='start_date', ascending=False)\n",
    "    return edu_exp_df\n",
    "\n",
    "# filtering based on group and institution\n",
    "def filter_data(df, valid_groups, valid_institution):\n",
    "    mask = df.apply(lambda x: x.get('group') in valid_groups or x.get('institution') == valid_institution, axis=1)\n",
    "    return df[mask]\n",
    "\n",
    "# Load social links directly\n",
    "def load_social_links(social_dir):\n",
    "    social_links=None\n",
    "    social_links_file_path = social_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "    return social_links\n",
    "\n",
    "# Load topmost project title\n",
    "def load_latest_project_title(project_dir):\n",
    "    projects_file_path = project_dir / \"projects.json\"\n",
    "    topmost_project_title= None\n",
    "    if projects_file_path.exists():\n",
    "        projects_df = pd.read_json(projects_file_path)\n",
    "        if not projects_df.empty:\n",
    "            topmost_project_title = projects_df.iloc[0].get(\"project_title\")\n",
    "    return topmost_project_title\n",
    "\n",
    "def parse_member_data(member_dir):\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_df = load_education_experience_data(member_json_dir)\n",
    "    current_project_title = load_latest_project_title(member_json_dir)\n",
    "    social_links = load_social_links(member_json_dir)\n",
    "    return education_experience_df, social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    \"\"\"\n",
    "    Extract the current academic role of a member based on education and experience data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    education_experience_df : pandas.DataFrame\n",
    "        DataFrame containing education and experience data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, bool]\n",
    "        A tuple containing:\n",
    "        - str: The current academic role of the member.\n",
    "        - bool: True if the member is currently active, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    role_map = {\n",
    "        \"Assistant Professor\": \"Professor\",\n",
    "        \"Professor\": \"Professor\",\n",
    "        \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "        \"Research Consultant\": \"Research Consultant\",\n",
    "        \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "        \"Professorial Assistant\": \"Undergraduate\",\n",
    "        \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "        \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "    }\n",
    "\n",
    "    degree_map = {\n",
    "        \"Masters\": \"Graduate Student\",\n",
    "        \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "        \"Bachelors\": \"Graduate Student\",\n",
    "    }\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = role_map.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\"  # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in degree_map:\n",
    "                current_academic_role = degree_map[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "def fetch_member_data():\n",
    "    \"\"\"\n",
    "    Fetch and process member data from directories in the specified members' directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[list, list]\n",
    "        A tuple containing two lists:\n",
    "        1. List of dictionaries representing current members' data.\n",
    "        2. List of dictionaries representing alumni members' data.\n",
    "\n",
    "    \"\"\"\n",
    "    current_people_page_list = []\n",
    "    alumni_people_page_list = []\n",
    "    # Looping through member directories to fetch and process member data\n",
    "    for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "        print(member_dir)\n",
    "        if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "            continue\n",
    "        else:\n",
    "            member_info = json.load(open(member_info_fname, \"r\"))\n",
    "        education_experience_df, social_links, current_project_title = parse_member_data(\n",
    "            member_dir\n",
    "        )\n",
    "        current_academic_role, is_current_member = extract_member_academic_role(\n",
    "            education_experience_df\n",
    "        )\n",
    "    \n",
    "        first_name = member_info[\"first_name\"]\n",
    "        last_name = member_info[\"last_name\"]\n",
    "        nickname = member_info.get(\"nick_name\", None)\n",
    "        id = member_info[\"id\"]\n",
    "        image_path = member_info[\"image_path\"]\n",
    "        cover_image_path = member_info[\"cover_image_path\"]\n",
    "    \n",
    "        name = f\"{nickname if nickname else first_name} {last_name}\"\n",
    "    \n",
    "        member_data = {\n",
    "            \"name\": name,\n",
    "            \"academic_role\": current_academic_role,\n",
    "            \"id\": id,\n",
    "            \"current_project_title\": current_project_title,\n",
    "            \"image_path\": image_path,\n",
    "            \"cover_image_path\": cover_image_path,\n",
    "        }\n",
    "    \n",
    "        if social_links is not None:\n",
    "            member_data.update(social_links)\n",
    "    \n",
    "        if is_current_member:\n",
    "            current_people_page_list.append(member_data)\n",
    "        else:\n",
    "            alumni_people_page_list.append(member_data)\n",
    "    return current_people_page_list, alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../group-data/members/sofia_biriouk\n",
      "../../group-data/members/jack_o_brien\n",
      "../../group-data/members/jack_o_brien/jsons/experiences.json does not exist\n",
      "../../group-data/members/josh_shields\n",
      "../../group-data/members/hayden_monk\n",
      "../../group-data/members/hayden_monk/jsons/experiences.json does not exist\n",
      "../../group-data/members/vicente_amado\n",
      "../../group-data/members/vicente_amado/jsons/experiences.json does not exist\n",
      "../../group-data/members/jing_lu\n",
      "../../group-data/members/kevin_cawley\n",
      "../../group-data/members/yuki_matsumura\n",
      "../../group-data/members/yuki_matsumura/jsons/experiences.json does not exist\n",
      "../../group-data/members/atharva_arya\n",
      "../../group-data/members/wolfgang_kerzendorf\n",
      "../../group-data/members/abhinav_ohri\n",
      "../../group-data/members/sona_chitchyan\n",
      "../../group-data/members/sona_chitchyan/jsons/education.json does not exist\n",
      "../../group-data/members/bea_lu\n",
      "../../group-data/members/alexander_grunewald\n",
      "../../group-data/members/alexander_grunewald/jsons/experiences.json does not exist\n",
      "../../group-data/members/harshul_gupta\n",
      "../../group-data/members/benjamin_mellon\n",
      "../../group-data/members/benjamin_mellon/jsons/experiences.json does not exist\n",
      "../../group-data/members/benjamin_mellon/jsons/education.json does not exist\n",
      "../../group-data/members/erin_visser\n",
      "../../group-data/members/andrew_fullard\n",
      "../../group-data/members/jaladh_singhal\n",
      "../../group-data/members/isaac_smith\n",
      "../../group-data/members/richard_dow\n",
      "../../group-data/members/cecelia_powers\n",
      "../../group-data/members/anirban_dutta\n",
      "../../group-data/members/iliomar_rodriguez_ramos\n"
     ]
    }
   ],
   "source": [
    "current_people_page_list, alumni_people_page_list = fetch_member_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page('people.html.j2', 'People.html',  general=data[\"general\"], current_members=current_people_page_list, alumni_members=alumni_people_page_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page('contact.html.j2', 'Contact.html', general=data[\"general\"], contact=data[\"contact\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page('support.html.j2', 'Support.html', general=data[\"general\"], support=data[\"support\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render front pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_extended = article_columns_initial + [\"author_id\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "research_content_df = content_df[content_df['category'] != 'News'].sort_values(by=['category', 'date'], ascending=[True, False])\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_page('research.html.j2', 'Research.html', general=data[\"general\"], content=research_content_df, research=data[\"research\"] , current_members=current_people_page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_research_template = environment.get_template(\"sub_research_frontpage.html.j2\")\n",
    "\n",
    "\n",
    "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
    "        sub_research_content = sub_research_template.render(general=data[\"general\"], \n",
    "                                                            research=data[\"research\"], \n",
    "                                                            content = latest_content_df,\n",
    "                                                            category = category,\n",
    "                                                            current_members=current_people_page_list\n",
    "                                                            )\n",
    "        folder_path = f\"{HOSTING_PATH}/sub_research/{page_link(category.lower())}\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        with open(f\"{folder_path}.html\", mode=\"w\", encoding=\"utf-8\") as sub_research:\n",
    "            sub_research.write(sub_research_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
